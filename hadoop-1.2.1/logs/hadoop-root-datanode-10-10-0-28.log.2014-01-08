2014-01-08 17:34:06,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = 10-10-0-28/10.10.0.28
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.2-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'root' on Wed Jan  8 17:33:13 EST 2014
STARTUP_MSG:   java = 1.7.0_09-icedtea
************************************************************/
2014-01-08 17:34:06,653 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-01-08 17:34:06,706 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-01-08 17:34:06,722 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-01-08 17:34:06,722 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2014-01-08 17:34:06,930 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-01-08 17:34:07,115 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2014-01-08 17:34:07,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Permitting datanode version '1.2.2-SNAPSHOT' and revision '' to connect to namenode version '1.2.2-SNAPSHOT' and revision '' because hadoop.skip.worker.version.check is enabled
2014-01-08 17:34:07,634 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-root/dfs/data is not formatted
2014-01-08 17:34:07,634 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2014-01-08 17:34:08,189 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Registered FSDatasetStatusMBean
2014-01-08 17:34:08,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened data transfer server at 50010
2014-01-08 17:34:08,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2014-01-08 17:34:08,348 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-01-08 17:34:08,431 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-01-08 17:34:08,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dfs.webhdfs.enabled = false
2014-01-08 17:34:08,513 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50075
2014-01-08 17:34:08,514 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50075 webServer.getConnectors()[0].getLocalPort() returned 50075
2014-01-08 17:34:08,514 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50075
2014-01-08 17:34:08,514 INFO org.mortbay.log: jetty-6.1.26
2014-01-08 17:34:09,113 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50075
2014-01-08 17:34:09,130 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-01-08 17:34:09,132 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source DataNode registered.
2014-01-08 17:34:09,273 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2014-01-08 17:34:09,288 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort50020 registered.
2014-01-08 17:34:09,289 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort50020 registered.
2014-01-08 17:34:09,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnRegistration = DatanodeRegistration(hadoop-6:50010, storageID=, infoPort=50075, ipcPort=50020)
2014-01-08 17:34:35,912 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: New storage id DS-66968297-10.10.0.28-50010-1389220475866 is assigned to data-node 10.10.0.28:50010
2014-01-08 17:34:35,926 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished generating blocks being written report for 1 volumes in 0 seconds
2014-01-08 17:34:35,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 1ms
2014-01-08 17:34:35,936 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.10.0.28:50010, storageID=DS-66968297-10.10.0.28-50010-1389220475866, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/tmp/hadoop-root/dfs/data/current'}
2014-01-08 17:34:35,937 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-01-08 17:34:35,937 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2014-01-08 17:34:35,940 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2014-01-08 17:34:35,941 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2014-01-08 17:34:35,941 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2014-01-08 17:34:35,943 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2014-01-08 17:34:35,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 1 msecs for RPC and NN processing
2014-01-08 17:34:35,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting Periodic block scanner
2014-01-08 17:34:35,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated rough (lockless) block report in 0 ms
2014-01-08 17:35:08,954 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Call to hadoop-1/10.10.0.7:8020 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1150)
	at org.apache.hadoop.ipc.Client.call(Client.java:1118)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:230)
	at sun.proxy.$Proxy5.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.offerService(DataNode.java:1033)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.run(DataNode.java:1644)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:845)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:790)

2014-01-08 17:35:13,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at 10-10-0-28/10.10.0.28
************************************************************/
2014-01-08 17:35:28,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = 10-10-0-28/10.10.0.28
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.2.2-SNAPSHOT
STARTUP_MSG:   build =  -r ; compiled by 'root' on Wed Jan  8 17:34:44 EST 2014
STARTUP_MSG:   java = 1.7.0_09-icedtea
************************************************************/
2014-01-08 17:35:28,811 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-01-08 17:35:28,840 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source MetricsSystem,sub=Stats registered.
2014-01-08 17:35:28,841 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-01-08 17:35:28,841 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2014-01-08 17:35:28,981 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source ugi registered.
2014-01-08 17:35:29,020 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2014-01-08 17:35:29,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Permitting datanode version '1.2.2-SNAPSHOT' and revision '' to connect to namenode version '1.2.2-SNAPSHOT' and revision '' because hadoop.skip.worker.version.check is enabled
2014-01-08 17:35:29,232 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-root/dfs/data is not formatted
2014-01-08 17:35:29,232 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2014-01-08 17:35:29,379 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Registered FSDatasetStatusMBean
2014-01-08 17:35:29,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened data transfer server at 50010
2014-01-08 17:35:29,398 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2014-01-08 17:35:29,462 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-01-08 17:35:29,559 INFO org.apache.hadoop.http.HttpServer: Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-01-08 17:35:29,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dfs.webhdfs.enabled = false
2014-01-08 17:35:29,578 INFO org.apache.hadoop.http.HttpServer: Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 50075
2014-01-08 17:35:29,579 INFO org.apache.hadoop.http.HttpServer: listener.getLocalPort() returned 50075 webServer.getConnectors()[0].getLocalPort() returned 50075
2014-01-08 17:35:29,579 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 50075
2014-01-08 17:35:29,579 INFO org.mortbay.log: jetty-6.1.26
2014-01-08 17:35:30,068 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:50075
2014-01-08 17:35:30,072 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source jvm registered.
2014-01-08 17:35:30,073 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source DataNode registered.
2014-01-08 17:35:30,113 INFO org.apache.hadoop.ipc.Server: Starting SocketReader
2014-01-08 17:35:30,116 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcDetailedActivityForPort50020 registered.
2014-01-08 17:35:30,116 INFO org.apache.hadoop.metrics2.impl.MetricsSourceAdapter: MBean for source RpcActivityForPort50020 registered.
2014-01-08 17:35:30,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnRegistration = DatanodeRegistration(hadoop-6:50010, storageID=, infoPort=50075, ipcPort=50020)
2014-01-08 17:35:30,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: New storage id DS-949654102-10.10.0.28-50010-1389220530125 is assigned to data-node 10.10.0.28:50010
2014-01-08 17:35:30,151 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished generating blocks being written report for 1 volumes in 0 seconds
2014-01-08 17:35:30,153 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 0ms
2014-01-08 17:35:30,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(10.10.0.28:50010, storageID=DS-949654102-10.10.0.28-50010-1389220530125, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/tmp/hadoop-root/dfs/data/current'}
2014-01-08 17:35:30,156 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2014-01-08 17:35:30,156 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2014-01-08 17:35:30,156 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2014-01-08 17:35:30,156 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2014-01-08 17:35:30,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2014-01-08 17:35:30,157 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2014-01-08 17:35:30,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 1 msecs for RPC and NN processing
2014-01-08 17:35:30,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting Periodic block scanner
2014-01-08 17:35:30,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated rough (lockless) block report in 0 ms
2014-01-08 18:22:49,104 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 0ms
2014-01-08 18:22:52,121 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 16 msecs for RPC and NN processing
2014-01-08 19:22:47,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 0ms
2014-01-08 19:22:50,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 17 msecs for RPC and NN processing
2014-01-08 20:22:48,535 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 0ms
2014-01-08 20:22:51,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 18 msecs for RPC and NN processing
2014-01-08 21:22:49,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 0ms
2014-01-08 21:22:52,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 16 msecs for RPC and NN processing
2014-01-08 22:22:47,970 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 0ms
2014-01-08 22:22:50,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 18 msecs for RPC and NN processing
2014-01-08 23:22:49,186 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Finished asynchronous block report scan in 1ms
2014-01-08 23:22:52,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 17 msecs for RPC and NN processing
